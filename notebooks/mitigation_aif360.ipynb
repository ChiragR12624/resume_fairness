{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset: data/cleaned_resume.csv\n",
      "                                         resume_text  gender  label\n",
      "0  Experienced software engineer skilled in Pytho...    male      1\n",
      "1  Frontend developer with React and JavaScript e...  female      1\n",
      "2             Data analyst with SQL and R experience    male      0\n",
      "3           Marketing specialist with SEO background  female      0\n",
      "4                       AI researcher with NLP focus    male      1\n",
      "AIF360 dataset created. features shape: (5, 53)\n",
      "Baseline: {'Method': 'Baseline', 'Accuracy': 0.5, 'F1': 0.6666666666666666, 'SPD': np.float64(nan), 'EOD': np.float64(nan)}\n",
      "Reweighing: {'Method': 'Reweighing', 'Accuracy': 0.5, 'F1': 0.6666666666666666, 'SPD': np.float64(nan), 'EOD': np.float64(nan)}\n",
      "Official DisparateImpactRemover NOT available (missing dependency). Falling back to residualization repair.\n",
      "Running residualization fallback (linear removal of protected attribute signal).\n",
      "DIR fallback metrics: {'Method': 'DIR_fallback_residualize', 'Accuracy': 0.5, 'F1': 0.6666666666666666, 'SPD': np.float64(nan), 'EOD': np.float64(nan)}\n",
      "\n",
      "Saved results to reports/day9_bias_mitigation_results.csv\n",
      "                     Method  Accuracy        F1  SPD  EOD\n",
      "0                  Baseline       0.5  0.666667  NaN  NaN\n",
      "1                Reweighing       0.5  0.666667  NaN  NaN\n",
      "2  DIR_fallback_residualize       0.5  0.666667  NaN  NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:673: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (self.num_pred_positives(privileged=privileged)\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/algorithms/preprocessing/reweighing.py:67: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  self.w_p_unfav = n_unfav*n_p / (n*n_p_unfav)\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:673: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (self.num_pred_positives(privileged=privileged)\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:673: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (self.num_pred_positives(privileged=privileged)\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "/Users/chiragrgowda/Documents/resume-fairness/venv/lib/python3.13/site-packages/aif360/metrics/classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plots saved to reports/:\n",
      " - day9_performance.png\n",
      " - day9_fairness.png\n",
      " - day9_tradeoff_accuracy_spd.png\n",
      " - day9_tradeoff_accuracy_eod.png\n",
      " - day9_radar.png\n",
      "\n",
      "✅ Day 9 completed. If you want, I can now:\n",
      "  • help interpret the metrics (short write-up),\n",
      "  • add post-processing mitigators (Day 10),\n",
      "  • or prepare a polished PDF/slide with the reports/ images.\n"
     ]
    }
   ],
   "source": [
    "# Day 9 — Bias Mitigation (with robust DIR fallback)\n",
    "# Paste into a notebook cell and run.\n",
    "# Requirements: aif360, scikit-learn, pandas, numpy, matplotlib, seaborn\n",
    "# If you can install packages, run:\n",
    "#   pip install aif360 BlackBoxAuditing seaborn\n",
    "# Then run this cell.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load dataset (robust)\n",
    "# -----------------------------\n",
    "# tries common paths; will create small dummy dataset if none found\n",
    "candidates = [\"data/cleaned_resume.csv\", \"notebooks/data/cleaned_resume.csv\", \"cleaned_resume.csv\"]\n",
    "csv_path = None\n",
    "for p in candidates:\n",
    "    if os.path.exists(p):\n",
    "        csv_path = p\n",
    "        break\n",
    "\n",
    "if csv_path is None:\n",
    "    for root, _, files in os.walk(\".\"):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".csv\") and \"cleaned\" in f.lower() and \"resume\" in f.lower():\n",
    "                csv_path = os.path.join(root, f)\n",
    "                break\n",
    "        if csv_path:\n",
    "            break\n",
    "\n",
    "if csv_path is None:\n",
    "    print(\"No cleaned_resume.csv found — creating small dummy dataset at data/cleaned_resume.csv\")\n",
    "    df = pd.DataFrame({\n",
    "        \"resume_text\": [\n",
    "            \"Experienced software engineer skilled in Python and ML\",\n",
    "            \"Frontend developer with React and JavaScript expertise\",\n",
    "            \"Data analyst with SQL and R experience\",\n",
    "            \"Marketing specialist with SEO background\",\n",
    "            \"AI researcher with NLP focus\",\n",
    "            \"Junior developer with Python experience\",\n",
    "            \"Senior data scientist with deep learning experience\",\n",
    "            \"Product manager with strong communication skills\"\n",
    "        ],\n",
    "        \"gender\": [\"male\", \"female\", \"male\", \"female\", \"male\", \"female\", \"male\", \"female\"],\n",
    "        \"label\": [1,1,0,0,1,0,1,0]\n",
    "    })\n",
    "    csv_path = \"data/cleaned_resume.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Using dataset:\", csv_path)\n",
    "print(df.head())\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Sanity: required columns\n",
    "# -----------------------------\n",
    "for col in [\"resume_text\",\"gender\",\"label\"]:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "# Map gender to numeric (male=1 privileged, female=0 unprivileged)\n",
    "df['gender_mapped'] = df['gender'].map(lambda x: 1 if str(x).strip().lower()==\"male\" else 0).astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Text -> numeric via TF-IDF\n",
    "# -----------------------------\n",
    "tfidf = TfidfVectorizer(max_features=200, ngram_range=(1,2))\n",
    "X_text = tfidf.fit_transform(df['resume_text'].fillna(\"\")).toarray()\n",
    "tf_cols = [f\"tfidf_{i}\" for i in range(X_text.shape[1])]\n",
    "df_tf = pd.DataFrame(X_text, columns=tf_cols, index=df.index)\n",
    "\n",
    "df_num = pd.concat([df_tf, df[['gender_mapped','label']]], axis=1)\n",
    "df_num = df_num.rename(columns={\"gender_mapped\":\"gender\"})  # AIF360 expects the protected attr name in df\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Create AIF360 StandardDataset\n",
    "# -----------------------------\n",
    "aif_ds = StandardDataset(\n",
    "    df_num,\n",
    "    label_name='label',\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=['gender'],\n",
    "    privileged_classes=[[1]]\n",
    ")\n",
    "print(\"AIF360 dataset created. features shape:\", aif_ds.features.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Train/test split (AIF360)\n",
    "# -----------------------------\n",
    "train, test = aif_ds.split([0.7], shuffle=True)\n",
    "X_train, y_train = train.features, train.labels.ravel()\n",
    "X_test, y_test = test.features, test.labels.ravel()\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Helper: compute metrics via AIF360 ClassificationMetric\n",
    "# -----------------------------\n",
    "def compute_metrics(aif_test, y_pred, method):\n",
    "    aif_pred = aif_test.copy()\n",
    "    aif_pred.labels = y_pred.reshape(-1,1)\n",
    "    metric = ClassificationMetric(aif_test, aif_pred,\n",
    "                                  unprivileged_groups=[{'gender': 0}],\n",
    "                                  privileged_groups=[{'gender': 1}])\n",
    "    acc = accuracy_score(aif_test.labels.ravel(), y_pred)\n",
    "    f1 = f1_score(aif_test.labels.ravel(), y_pred, zero_division=0)\n",
    "    spd = metric.statistical_parity_difference()\n",
    "    eod = metric.equal_opportunity_difference()\n",
    "    return {'Method': method, 'Accuracy': acc, 'F1': f1, 'SPD': spd, 'EOD': eod}\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Baseline\n",
    "# -----------------------------\n",
    "clf_base = LogisticRegression(max_iter=1000)\n",
    "clf_base.fit(X_train, y_train)\n",
    "y_base = clf_base.predict(X_test)\n",
    "base_metrics = compute_metrics(test, y_base, \"Baseline\")\n",
    "print(\"Baseline:\", base_metrics)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Reweighing (pre-processing)\n",
    "# -----------------------------\n",
    "rw = Reweighing(unprivileged_groups=[{'gender':0}], privileged_groups=[{'gender':1}])\n",
    "rw.fit(train)\n",
    "train_rw = rw.transform(train)  # includes instance_weights\n",
    "\n",
    "clf_rw = LogisticRegression(max_iter=1000)\n",
    "clf_rw.fit(train_rw.features, train_rw.labels.ravel(), sample_weight=train_rw.instance_weights)\n",
    "y_rw = clf_rw.predict(X_test)\n",
    "rw_metrics = compute_metrics(test, y_rw, \"Reweighing\")\n",
    "print(\"Reweighing:\", rw_metrics)\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Try to use official DIR; fallback if BlackBoxAuditing not installed\n",
    "# -----------------------------\n",
    "use_official_dir = True\n",
    "try:\n",
    "    # attempt to import and construct the official DIR (this import happens inside AIF360 object)\n",
    "    from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "    # create instance to check dependency\n",
    "    _ = DisparateImpactRemover(repair_level=1.0)\n",
    "    print(\"Official DisparateImpactRemover available.\")\n",
    "except Exception as e:\n",
    "    print(\"Official DisparateImpactRemover NOT available (missing dependency). Falling back to residualization repair.\")\n",
    "    # print(e)\n",
    "    use_official_dir = False\n",
    "\n",
    "if use_official_dir:\n",
    "    # Official path\n",
    "    DIR = DisparateImpactRemover(repair_level=1.0)\n",
    "    train_dir = DIR.fit_transform(train)\n",
    "    test_dir = DIR.transform(test)\n",
    "    clf_dir = LogisticRegression(max_iter=1000)\n",
    "    clf_dir.fit(train_dir.features, train_dir.labels.ravel())\n",
    "    y_dir = clf_dir.predict(test_dir.features)\n",
    "    dir_metrics = compute_metrics(test_dir, y_dir, \"DisparateImpactRemover\")\n",
    "    print(\"DIR (official) metrics:\", dir_metrics)\n",
    "else:\n",
    "    # Fallback: residualize each numeric feature to remove linear dependence on protected attribute\n",
    "    # Train residualizers on TRAIN features using TRAIN protected attribute\n",
    "    print(\"Running residualization fallback (linear removal of protected attribute signal).\")\n",
    "    # prepare numpy arrays\n",
    "    Xtr = train.features  # shape (n_train, n_features)\n",
    "    Xte = test.features\n",
    "    prot_tr = train.protected_attributes[:, 0].reshape(-1,1)  # gender 0/1\n",
    "    # Fit linear regression per feature: X_feature ~ prot_tr and compute residuals\n",
    "    lr = LinearRegression()\n",
    "    Xtr_res = np.zeros_like(Xtr)\n",
    "    Xte_res = np.zeros_like(Xte)\n",
    "    for j in range(Xtr.shape[1]):\n",
    "        # fit model feature_j ~ prot_tr\n",
    "        lr.fit(prot_tr, Xtr[:, j])\n",
    "        pred_tr = lr.predict(prot_tr)\n",
    "        res_tr = Xtr[:, j] - pred_tr\n",
    "        Xtr_res[:, j] = res_tr\n",
    "        # apply same model to test prot attribute\n",
    "        pred_te = lr.predict(test.protected_attributes[:,0].reshape(-1,1))\n",
    "        res_te = Xte[:, j] - pred_te\n",
    "        Xte_res[:, j] = res_te\n",
    "    # Now train classifier on residualized features\n",
    "    clf_dir = LogisticRegression(max_iter=1000)\n",
    "    clf_dir.fit(Xtr_res, train.labels.ravel())\n",
    "    y_dir = clf_dir.predict(Xte_res)\n",
    "    # For metric computation, we need a dataset object for test_dir-like shape\n",
    "    # We'll create copies of test and replace features with Xte_res\n",
    "    test_dir = test.copy()\n",
    "    test_dir.features = Xte_res\n",
    "    dir_metrics = compute_metrics(test_dir, y_dir, \"DIR_fallback_residualize\")\n",
    "    print(\"DIR fallback metrics:\", dir_metrics)\n",
    "\n",
    "# -----------------------------\n",
    "# 10) Collect and save results\n",
    "# -----------------------------\n",
    "results = pd.DataFrame([base_metrics, rw_metrics, dir_metrics])[['Method','Accuracy','F1','SPD','EOD']]\n",
    "results.to_csv(\"reports/day9_bias_mitigation_results.csv\", index=False)\n",
    "print(\"\\nSaved results to reports/day9_bias_mitigation_results.csv\")\n",
    "print(results)\n",
    "\n",
    "# -----------------------------\n",
    "# 11) Plots and tradeoff charts\n",
    "# -----------------------------\n",
    "# Performance & fairness bar charts\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=results.melt(id_vars='Method', value_vars=['Accuracy','F1']),\n",
    "            x='Method', y='value', hue='variable')\n",
    "plt.title(\"Performance: Accuracy & F1\")\n",
    "plt.savefig(\"reports/day9_performance.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=results.melt(id_vars='Method', value_vars=['SPD','EOD']),\n",
    "            x='Method', y='value', hue='variable')\n",
    "plt.title(\"Fairness: SPD & EOD\")\n",
    "plt.savefig(\"reports/day9_fairness.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Trade-off plots\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.scatterplot(data=results, x='Accuracy', y='SPD', hue='Method', s=140)\n",
    "for _, r in results.iterrows():\n",
    "    plt.text(r['Accuracy']+1e-4, r['SPD'], r['Method'])\n",
    "plt.axhline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Accuracy vs SPD\")\n",
    "plt.savefig(\"reports/day9_tradeoff_accuracy_spd.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.scatterplot(data=results, x='Accuracy', y='EOD', hue='Method', s=140)\n",
    "for _, r in results.iterrows():\n",
    "    plt.text(r['Accuracy']+1e-4, r['EOD'], r['Method'])\n",
    "plt.axhline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Accuracy vs EOD\")\n",
    "plt.savefig(\"reports/day9_tradeoff_accuracy_eod.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Radar chart (normalized)\n",
    "metrics_plot = results.copy()\n",
    "metrics_plot['Accuracy_n'] = (metrics_plot['Accuracy'] - metrics_plot['Accuracy'].min()) / (metrics_plot['Accuracy'].max() - metrics_plot['Accuracy'].min() + 1e-9)\n",
    "metrics_plot['SPD_n'] = 1 - (np.abs(metrics_plot['SPD']) - np.abs(metrics_plot['SPD']).min()) / (np.abs(metrics_plot['SPD']).max() - np.abs(metrics_plot['SPD']).min() + 1e-9)\n",
    "metrics_plot['EOD_n'] = 1 - (np.abs(metrics_plot['EOD']) - np.abs(metrics_plot['EOD']).min()) / (np.abs(metrics_plot['EOD']).max() - np.abs(metrics_plot['EOD']).min() + 1e-9)\n",
    "\n",
    "plot_cols = ['Accuracy_n','SPD_n','EOD_n']\n",
    "labels = ['Accuracy','Fairness SPD (higher→better)','Fairness EOD (higher→better)']\n",
    "\n",
    "angles = np.linspace(0,2*np.pi,len(plot_cols),endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "for _, row in metrics_plot.iterrows():\n",
    "    vals = row[plot_cols].tolist()\n",
    "    vals += vals[:1]\n",
    "    ax.plot(angles, vals, linewidth=2, label=row['Method'])\n",
    "    ax.fill(angles, vals, alpha=0.15)\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "ax.set_ylim(0,1)\n",
    "plt.title(\"Radar: Accuracy vs Fairness (normalized)\")\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3,1.1))\n",
    "plt.savefig(\"reports/day9_radar.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"✅ Plots saved to reports/:\")\n",
    "print(\" - day9_performance.png\")\n",
    "print(\" - day9_fairness.png\")\n",
    "print(\" - day9_tradeoff_accuracy_spd.png\")\n",
    "print(\" - day9_tradeoff_accuracy_eod.png\")\n",
    "print(\" - day9_radar.png\")\n",
    "\n",
    "print(\"\\n✅ Day 9 completed. If you want, I can now:\")\n",
    "print(\"  • help interpret the metrics (short write-up),\")\n",
    "print(\"  • add post-processing mitigators (Day 10),\")\n",
    "print(\"  • or prepare a polished PDF/slide with the reports/ images.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
